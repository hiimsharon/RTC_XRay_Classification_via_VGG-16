{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7164e3b-22ff-42aa-bd02-cdeac5cf526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "intact_dir = \"/home/jovyan/test_sha/RTC_0514/intact\"\n",
    "tear_dir = \"/home/jovyan/test_sha/RTC_0514/tear\"\n",
    "\n",
    "num_train_per_class = 205\n",
    "num_test_intact = 30\n",
    "num_test_tear = 107\n",
    "num_folds = 5\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "img_height, img_width, channels = 224, 224, 3\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  \n",
    "    return image\n",
    "\n",
    "intact_images_paths = [os.path.join(intact_dir, img) for img in os.listdir(intact_dir)]\n",
    "tear_images_paths = [os.path.join(tear_dir, img) for img in os.listdir(tear_dir)]\n",
    "\n",
    "random.seed(42)\n",
    "intact_train_paths = random.sample(intact_images_paths, num_train_per_class)\n",
    "tear_train_paths = random.sample(tear_images_paths, num_train_per_class)\n",
    "\n",
    "intact_test_paths = random.sample(intact_images_paths, num_test_intact)\n",
    "tear_test_paths = random.sample(tear_images_paths, num_test_tear)\n",
    "\n",
    "intact_train_images = [load_and_preprocess_image(img) for img in intact_train_paths]\n",
    "tear_train_images = [load_and_preprocess_image(img) for img in tear_train_paths]\n",
    "intact_test_images = [load_and_preprocess_image(img) for img in intact_test_paths]\n",
    "tear_test_images = [load_and_preprocess_image(img) for img in tear_test_paths]\n",
    "\n",
    "intact_train_labels = [0] * len(intact_train_images)\n",
    "tear_train_labels = [1] * len(tear_train_images)\n",
    "intact_test_labels = [0] * len(intact_test_images)\n",
    "tear_test_labels = [1] * len(tear_test_images)\n",
    "\n",
    "train_images = np.array(intact_train_images + tear_train_images)\n",
    "train_labels = np.array(intact_train_labels + tear_train_labels)\n",
    "test_images = np.array(intact_test_images + tear_test_images)\n",
    "test_labels = np.array(intact_test_labels + tear_test_labels)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, channels))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_vgg = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_vgg.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_accuracy', target_accuracy=0.99, consecutive_epochs=5):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.target_accuracy = target_accuracy\n",
    "        self.consecutive_epochs = consecutive_epochs\n",
    "        self.count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get(self.monitor)\n",
    "        if (current_accuracy is not None) and (current_accuracy >= self.target_accuracy):\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.count = 0\n",
    "\n",
    "        if self.count >= self.consecutive_epochs:\n",
    "            print(f\"\\nReached target accuracy of {self.target_accuracy} for {self.consecutive_epochs} consecutive epochs. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0.00001)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "train_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "test_generator = datagen.flow(test_images, test_labels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold = 0\n",
    "accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n",
    "\n",
    "for train_index, test_index in kf.split(train_images):\n",
    "    fold += 1\n",
    "    print(f\"\\nFold {fold}/{num_folds}\")\n",
    "\n",
    "    X_train, X_val = train_images[train_index], train_images[test_index]\n",
    "    y_train, y_val = train_labels[train_index], train_labels[test_index]\n",
    "\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    history = model_vgg.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[early_stop, custom_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    y_pred = model_vgg.predict(val_generator)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f\"Fold {fold} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "\n",
    "\n",
    "print(\"\\nCross Validation Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracy_scores)} ± {np.std(accuracy_scores)}\")\n",
    "print(f\"Mean Precision: {np.mean(precision_scores)} ± {np.std(precision_scores)}\")\n",
    "print(f\"Mean Recall: {np.mean(recall_scores)} ± {np.std(recall_scores)}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores)} ± {np.std(f1_scores)}\")\n",
    "\n",
    "history = model_vgg.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stop, custom_callback]\n",
    ")\n",
    "\n",
    "y_true = test_generator.y\n",
    "y_pred = model_vgg.predict(test_generator)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "save_dir = '/home/jovyan/test_sha/RTC_0514/data/04'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_path = os.path.join(save_dir, 'model.h5')\n",
    "model_vgg.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb089b8-64bc-46c4-9c9c-8780d6c63777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "intact_dir = \"/home/jovyan/test_sha/RTC_0514/intact\"\n",
    "tear_dir = \"/home/jovyan/test_sha/RTC_0514/tear\"\n",
    "\n",
    "num_train_per_class = 205\n",
    "num_test_intact = 30\n",
    "num_test_tear = 107\n",
    "num_folds = 5\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "img_height, img_width, channels = 224, 224, 3\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  \n",
    "    return image\n",
    "\n",
    "intact_images_paths = [os.path.join(intact_dir, img) for img in os.listdir(intact_dir)]\n",
    "tear_images_paths = [os.path.join(tear_dir, img) for img in os.listdir(tear_dir)]\n",
    "\n",
    "random.seed(42)\n",
    "intact_train_paths = random.sample(intact_images_paths, num_train_per_class)\n",
    "tear_train_paths = random.sample(tear_images_paths, num_train_per_class)\n",
    "\n",
    "intact_test_paths = random.sample(intact_images_paths, num_test_intact)\n",
    "tear_test_paths = random.sample(tear_images_paths, num_test_tear)\n",
    "\n",
    "intact_train_images = [load_and_preprocess_image(img) for img in intact_train_paths]\n",
    "tear_train_images = [load_and_preprocess_image(img) for img in tear_train_paths]\n",
    "intact_test_images = [load_and_preprocess_image(img) for img in intact_test_paths]\n",
    "tear_test_images = [load_and_preprocess_image(img) for img in tear_test_paths]\n",
    "\n",
    "intact_train_labels = [0] * len(intact_train_images)\n",
    "tear_train_labels = [1] * len(tear_train_images)\n",
    "intact_test_labels = [0] * len(intact_test_images)\n",
    "tear_test_labels = [1] * len(tear_test_images)\n",
    "\n",
    "train_images = np.array(intact_train_images + tear_train_images)\n",
    "train_labels = np.array(intact_train_labels + tear_train_labels)\n",
    "test_images = np.array(intact_test_images + tear_test_images)\n",
    "test_labels = np.array(intact_test_labels + tear_test_labels)\n",
    "\n",
    "# 建立VGG模型\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, channels))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_vgg = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_vgg.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_accuracy', target_accuracy=0.99, consecutive_epochs=5):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.target_accuracy = target_accuracy\n",
    "        self.consecutive_epochs = consecutive_epochs\n",
    "        self.count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get(self.monitor)\n",
    "        if (current_accuracy is not None) and (current_accuracy >= self.target_accuracy):\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.count = 0\n",
    "\n",
    "        if self.count >= self.consecutive_epochs:\n",
    "            print(f\"\\nReached target accuracy of {self.target_accuracy} for {self.consecutive_epochs} consecutive epochs. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0.00001)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "train_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "test_generator = datagen.flow(test_images, test_labels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold = 0\n",
    "accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n",
    "\n",
    "for train_index, test_index in kf.split(train_images):\n",
    "    fold += 1\n",
    "    print(f\"\\nFold {fold}/{num_folds}\")\n",
    "\n",
    "    X_train, X_val = train_images[train_index], train_images[test_index]\n",
    "    y_train, y_val = train_labels[train_index], train_labels[test_index]\n",
    "\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    history = model_vgg.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[early_stop, custom_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    y_pred = model_vgg.predict(val_generator)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"Fold {fold} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "\n",
    "print(\"\\nCross Validation Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracy_scores)} ± {np.std(accuracy_scores)}\")\n",
    "print(f\"Mean Precision: {np.mean(precision_scores)} ± {np.std(precision_scores)}\")\n",
    "print(f\"Mean Recall: {np.mean(recall_scores)} ± {np.std(recall_scores)}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores)} ± {np.std(f1_scores)}\")\n",
    "\n",
    "history = model_vgg.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stop, custom_callback]\n",
    ")\n",
    "\n",
    "y_true = test_generator.y\n",
    "y_pred = model_vgg.predict(test_generator)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "save_dir = '/home/jovyan/test_sha/RTC_0514/data/04'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_path = os.path.join(save_dir, 'model.h5')\n",
    "model_vgg.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cb8f8-ece9-4350-acd2-bdfde4f01611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tp = 24\n",
    "fp = 6\n",
    "fn = 20\n",
    "tn = 87\n",
    "\n",
    "conf_matrix = np.array([[tn, fp],\n",
    "                        [fn, tp]])\n",
    "\n",
    "labels = ['tear', 'intact']\n",
    "\n",
    "df_cm = pd.DataFrame(conf_matrix, index=labels, columns=labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "            xticklabels=labels, yticklabels=labels, annot_kws={\"size\": 15})\n",
    "plt.ylabel('Actual', fontsize=10)\n",
    "plt.xlabel('Predicted', fontsize=10)\n",
    "plt.title('Confusion Matrix_Fold 4', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb92b98-545b-4e3a-9b34-29e028dc8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "intact_dir = \"/home/jovyan/test_sha/RTC_0514/intact\"\n",
    "tear_dir = \"/home/jovyan/test_sha/RTC_0514/tear\"\n",
    "\n",
    "num_train_per_class = 205\n",
    "num_test_intact = 30\n",
    "num_test_tear = 107\n",
    "num_folds = 5\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "img_height, img_width, channels = 224, 224, 3\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  \n",
    "    return image\n",
    "\n",
    "intact_images_paths = [os.path.join(intact_dir, img) for img in os.listdir(intact_dir)]\n",
    "tear_images_paths = [os.path.join(tear_dir, img) for img in os.listdir(tear_dir)]\n",
    "\n",
    "random.seed(42)\n",
    "intact_train_paths = random.sample(intact_images_paths, num_train_per_class)\n",
    "tear_train_paths = random.sample(tear_images_paths, num_train_per_class)\n",
    "\n",
    "intact_test_paths = random.sample(intact_images_paths, num_test_intact)\n",
    "tear_test_paths = random.sample(tear_images_paths, num_test_tear)\n",
    "\n",
    "intact_train_images = [load_and_preprocess_image(img) for img in intact_train_paths]\n",
    "tear_train_images = [load_and_preprocess_image(img) for img in tear_train_paths]\n",
    "intact_test_images = [load_and_preprocess_image(img) for img in intact_test_paths]\n",
    "tear_test_images = [load_and_preprocess_image(img) for img in tear_test_paths]\n",
    "\n",
    "intact_train_labels = [0] * len(intact_train_images)\n",
    "tear_train_labels = [1] * len(tear_train_images)\n",
    "intact_test_labels = [0] * len(intact_test_images)\n",
    "tear_test_labels = [1] * len(tear_test_images)\n",
    "\n",
    "train_images = np.array(intact_train_images + tear_train_images)\n",
    "train_labels = np.array(intact_train_labels + tear_train_labels)\n",
    "test_images = np.array(intact_test_images + tear_test_images)\n",
    "test_labels = np.array(intact_test_labels + tear_test_labels)\n",
    "\n",
    "# 建立VGG模型\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, channels))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_vgg = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_vgg.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_accuracy', target_accuracy=0.99, consecutive_epochs=5):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.target_accuracy = target_accuracy\n",
    "        self.consecutive_epochs = consecutive_epochs\n",
    "        self.count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get(self.monitor)\n",
    "        if (current_accuracy is not None) and (current_accuracy >= self.target_accuracy):\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.count = 0\n",
    "\n",
    "        if self.count >= self.consecutive_epochs:\n",
    "            print(f\"\\nReached target accuracy of {self.target_accuracy} for {self.consecutive_epochs} consecutive epochs. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0.00001)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "train_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "test_generator = datagen.flow(test_images, test_labels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold = 0\n",
    "accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n",
    "\n",
    "for train_index, test_index in kf.split(train_images):\n",
    "    fold += 1\n",
    "    print(f\"\\nFold {fold}/{num_folds}\")\n",
    "\n",
    "    X_train, X_val = train_images[train_index], train_images[test_index]\n",
    "    y_train, y_val = train_labels[train_index], train_labels[test_index]\n",
    "\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    history = model_vgg.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[early_stop, custom_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    y_pred = model_vgg.predict(val_generator)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(\"\\nCross Validation Results:\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy} ± {std_accuracy}\")\n",
    "print(f\"Mean Precision: {mean_precision} ± {std_precision}\")\n",
    "print(f\"Mean Recall: {mean_recall} ± {std_recall}\")\n",
    "print(f\"Mean F1 Score: {mean_f1} ± {std_f1}\")\n",
    "\n",
    "history = model_vgg.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stop, custom_callback]\n",
    ")\n",
    "\n",
    "y_true = test_generator.y\n",
    "y_pred = model_vgg.predict(test_generator)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "save_dir = '/home/jovyan/test_sha/RTC_0514/data/04'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_path = os.path.join(save_dir, 'model.h5')\n",
    "model_vgg.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64014482-d593-4b4d-91c2-fd059b93000a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
